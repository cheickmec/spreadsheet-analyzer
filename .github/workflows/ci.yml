name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
    paths-ignore:
      - 'docs/**'
      - '**.md'
      - '.github/ISSUE_TEMPLATE/**'
      - '.github/pull_request_template.md'
      - 'LICENSE'
      - '.gitignore'

# Cancel in-progress runs when a new push is made
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  security-events: write
  actions: read
  checks: write
  pull-requests: write

env:
  PYTHON_VERSION: "3.12"
  UV_VERSION: "latest"
  MIN_COVERAGE: 50

jobs:
  lint-and-type-check:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "**/pyproject.toml"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run pre-commit hooks
        run: |
          uv run pre-commit run --all-files 2>&1 | tee lint-results.txt
        continue-on-error: true

      - name: Generate Linting Summary
        if: always()
        run: |
          echo "## 📝 Code Quality Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Generated at: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Ruff linting results
          echo "### Ruff Linting & Formatting" >> $GITHUB_STEP_SUMMARY
          if grep -q "Passed" lint-results.txt; then
            echo "✅ **Status**: All checks passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Status**: Issues found" >> $GITHUB_STEP_SUMMARY
            echo "<details><summary>View details</summary>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            grep -E "(Failed|error:|warning:)" lint-results.txt | head -20 >> $GITHUB_STEP_SUMMARY || true
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "</details>" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          # MyPy results
          echo "### Type Checking (MyPy)" >> $GITHUB_STEP_SUMMARY
          if uv run mypy src/; then
            echo "✅ **Status**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Status**: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          # Set exit code based on critical failures
          if grep -q "Failed" lint-results.txt; then
            exit 1
          fi

  test:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    services:
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "**/pyproject.toml"

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Install test dependencies
        run: |
          uv add --dev pytest-xdist pytest-timeout pytest-benchmark

      - name: Run tests with coverage
        run: |
          uv run pytest tests/ \
            --cov=src/spreadsheet_analyzer \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing:skip-covered \
            --cov-fail-under=${{ env.MIN_COVERAGE }} \
            -n auto \
            --timeout=300 \
            --benchmark-disable \
            -v
        env:
          REDIS_URL: redis://localhost:6379/0
          PYTHONPATH: ${{ github.workspace }}/src

      - name: Run benchmark tests
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          uv run pytest tests/benchmarks/ \
            --benchmark-only \
            --benchmark-json=benchmark_results.json \
            --benchmark-autosave
        continue-on-error: true

      - name: Generate Test Summary
        if: always()
        run: |
          echo "## 🧪 Test Coverage Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Overall Coverage" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY

          if [ -f coverage.xml ]; then
            COVERAGE=$(python -c "import xml.etree.ElementTree as ET; tree = ET.parse('coverage.xml'); root = tree.getroot(); print(f\"{float(root.get('line-rate', 0)) * 100:.1f}\")")
            echo "| **Line Coverage** | $COVERAGE% |" >> $GITHUB_STEP_SUMMARY
            echo "| **Minimum Required** | ${{ env.MIN_COVERAGE }}% |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| **Coverage** | ⚠️ Not available |" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📊 Full coverage report available in artifacts" >> $GITHUB_STEP_SUMMARY

      - name: Upload coverage reports
        uses: codecov/codecov-action@v5
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

      - name: Upload coverage HTML report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report
          path: htmlcov/
          retention-days: 7

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        with:
          name: benchmark-results
          path: benchmark_results.json
          retention-days: 30

  integration-test:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [lint-and-type-check, test]
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Download test Excel files
        run: |
          mkdir -p test_files
          # Download sample Excel files for integration testing
          curl -L -o test_files/simple.xlsx https://github.com/datasets/examples/raw/main/files/simple.xlsx || true
          curl -L -o test_files/financial.xlsx https://github.com/datasets/financial/raw/main/data/financial.xlsx || true

      - name: Run integration tests
        run: |
          uv run pytest tests/integration/ \
            --timeout=600 \
            -v \
            --tb=short \
            --no-cov
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_TEST }}
          TEST_FILES_DIR: ${{ github.workspace }}/test_files

      - name: Generate Integration Test Summary
        if: always()
        run: |
          echo "## 🔗 Integration Test Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Integration tests validate the complete analysis pipeline with real Excel files." >> $GITHUB_STEP_SUMMARY

  security-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run Bandit security scan
        run: |
          uv run bandit -r src/ -f json -o bandit-report.json
        continue-on-error: true

      - name: Run Safety check
        run: |
          uv run safety check --json > safety-report.json
        continue-on-error: true

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH,MEDIUM'
          skip-dirs: 'docs,tests'

      - name: Generate Security Summary
        if: always()
        run: |
          echo "## 🔒 Security Scan Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "### Bandit (Python Security)" >> $GITHUB_STEP_SUMMARY
          if [ -f bandit-report.json ]; then
            ISSUES=$(python -c "import json; data = json.load(open('bandit-report.json')); print(len(data.get('results', [])))")
            if [ "$ISSUES" = "0" ]; then
              echo "✅ **No security issues found**" >> $GITHUB_STEP_SUMMARY
            else
              echo "⚠️ **$ISSUES security issues found**" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "❌ **Scan failed**" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Safety (Dependency Check)" >> $GITHUB_STEP_SUMMARY
          if [ -f safety-report.json ]; then
            VULNS=$(python -c "import json; data = json.load(open('safety-report.json')); print(len(data.get('vulnerabilities', [])))" 2>/dev/null || echo "0")
            if [ "$VULNS" = "0" ]; then
              echo "✅ **No vulnerable dependencies**" >> $GITHUB_STEP_SUMMARY
            else
              echo "⚠️ **$VULNS vulnerable dependencies found**" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "❌ **Scan failed**" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json
            trivy-results.sarif
          retention-days: 30

  build-and-test-docker:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [test]
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          push: false
          tags: spreadsheet-analyzer:test
          cache-from: type=gha
          cache-to: type=gha,mode=max
          load: true

      - name: Test Docker image
        run: |
          # Test that the image runs successfully
          docker run --rm spreadsheet-analyzer:test

          # Test that Python and dependencies are available
          docker run --rm spreadsheet-analyzer:test python -c "import openpyxl; import defusedxml; print('Dependencies OK')"

      - name: Generate Docker Summary
        if: always()
        run: |
          echo "## 🐳 Docker Build Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ Docker image built and tested successfully" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Image Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Tag**: spreadsheet-analyzer:test" >> $GITHUB_STEP_SUMMARY
          echo "- **Base**: python:3.12-slim" >> $GITHUB_STEP_SUMMARY

  publish:
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    needs: [lint-and-type-check, test, integration-test, security-scan, build-and-test-docker]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      id-token: write
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          version: ${{ env.UV_VERSION }}

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Build package
        run: |
          uv build

      - name: Check package
        run: |
          uv run twine check dist/*

      # Note: Package publishing removed as this is proprietary software

      - name: Generate Publish Summary
        if: always()
        run: |
          echo "## 📦 Package Build Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Build Artifacts" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          ls -la dist/ >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
