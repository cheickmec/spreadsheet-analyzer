{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8421952f479",
   "metadata": {},
   "source": [
    "## Data Profiling Analysis\n",
    "\n",
    "Comprehensive statistical analysis and data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d4a9770c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data profiling imports\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238bec45c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Excel data\n",
    "file_path = r\"test_assets/collection/business-accounting/Business Accounting.xlsx\"\n",
    "sheet_name = \"Yiriden Transactions 2025\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    print(f\"‚úÖ Successfully loaded {len(df)} rows and {len(df.columns)} columns from Yiriden Transactions 2025\")\n",
    "    print(f\"üìä Data shape: {df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n",
    "    df = pd.DataFrame()  # Empty fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6581f9c0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Data Profiling for Yiriden Transactions 2025\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìã DATA PROFILING REPORT - Yiriden Transactions 2025\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Basic Information\n",
    "    print(\"\\nüîç BASIC INFORMATION\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "    # Column Information\n",
    "    print(\"\\nüìä COLUMN ANALYSIS\")\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        null_count = df[col].isnull().sum()\n",
    "        null_pct = (null_count / len(df)) * 100\n",
    "        unique_count = df[col].nunique()\n",
    "\n",
    "        print(f\"  {col:<30} | {dtype!s:<12} | Nulls: {null_count:>6} ({null_pct:>5.1f}%) | Unique: {unique_count:>6}\")\n",
    "\n",
    "    # Statistical Summary\n",
    "    print(\"\\nüìà STATISTICAL SUMMARY\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        display(df[numeric_cols].describe())\n",
    "    else:\n",
    "        print(\"No numeric columns found for statistical analysis\")\n",
    "\n",
    "    # Missing Values Analysis\n",
    "    print(\"\\n‚ùì MISSING VALUES ANALYSIS\")\n",
    "    missing_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"Column\": df.columns,\n",
    "            \"Missing_Count\": df.isnull().sum(),\n",
    "            \"Missing_Percentage\": (df.isnull().sum() / len(df)) * 100,\n",
    "        }\n",
    "    ).sort_values(\"Missing_Percentage\", ascending=False)\n",
    "\n",
    "    display(missing_summary[missing_summary[\"Missing_Count\"] > 0])\n",
    "\n",
    "    # Data Types Distribution\n",
    "    print(\"\\nüè∑Ô∏è DATA TYPES DISTRIBUTION\")\n",
    "    dtype_counts = df.dtypes.value_counts()\n",
    "    display(dtype_counts)\n",
    "\n",
    "    # Sample Data Preview\n",
    "    print(\"\\nüëÄ SAMPLE DATA PREVIEW\")\n",
    "    print(\"First 5 rows:\")\n",
    "    display(df.head())\n",
    "\n",
    "    if len(df) > 5:\n",
    "        print(\"\\nLast 5 rows:\")\n",
    "        display(df.tail())\n",
    "\n",
    "    # Quick Quality Checks\n",
    "    print(\"\\n‚úÖ QUICK QUALITY CHECKS\")\n",
    "\n",
    "    # Duplicate rows\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"Duplicate rows: {duplicate_count} ({duplicate_count / len(df) * 100:.1f}%)\")\n",
    "\n",
    "    # Empty rows\n",
    "    empty_rows = df.isnull().all(axis=1).sum()\n",
    "    print(f\"Completely empty rows: {empty_rows}\")\n",
    "\n",
    "    # Potential ID columns\n",
    "    potential_ids = [col for col in df.columns if df[col].nunique() == len(df) and not df[col].isnull().any()]\n",
    "    if potential_ids:\n",
    "        print(f\"Potential ID columns: {potential_ids}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No data available for profiling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1def6d84bb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*End of data_profiling*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
