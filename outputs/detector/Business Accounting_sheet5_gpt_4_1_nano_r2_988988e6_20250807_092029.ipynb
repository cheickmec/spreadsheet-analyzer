{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a82ace",
   "metadata": {
    "cell_id": "8da4ee84-646f-4afe-a11a-dede6b95a5fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sheet with shape: (47, 5)\n\nFirst 10 rows:\n                  Date                                       Item Amount (USD) Amount (CFA) Unnamed: 4\n0  2023-01-29 00:00:00                              Western Union    82.817929        50000        NaN\n1  2023-02-16 00:00:00                              Western Union       400.58       210000        NaN\n2  2023-04-27 00:00:00                               Sent to Papa     17096.69     10000000        NaN\n3  2023-05-30 00:00:00                   Sent to Yaya via Atchima       3414.2      2058000        NaN\n4  2023-06-02 00:00:00          Sent to Yaya via XE/Ria in Guinea       518.46       304168        NaN\n5  2023-06-06 00:00:00  Western Union to Abdoulaye Bamba for Yaya        48.41        28615        NaN\n6  2023-06-13 00:00:00                   Sent to Yaya via Atchima         5000      2994000        NaN\n7  2023-06-14 00:00:00                 Sent to Yaya via MoneyGram      1488.69       874000        NaN\n8  2023-06-21 00:00:00                 Sent to Yaya through Maman     37225.75     22000000        NaN\n9  2023-07-03 00:00:00            Sent to Yaya via XE/Ria in Mali      1668.96      1000000        NaN\n\nLast 5 rows:\n                Date     Item Amount (USD) Amount (CFA)  Unnamed: 4\n42  Chargement colis    37500    62.826347    62.826347           0\n43       Gazoil 200L   146000   244.603911   122.301956  122.301956\n44            Nattes     4000     6.701477     6.701477           0\n45     Shipping fees  2537550  4251.333256  4251.333256           0\n46             Total  3050050      5109.96   4862.00535   247.95465\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "excel_path = Path(r\"/Users/cheickberthe/PycharmProjects/spreadsheet-analyzer/test_assets/collection/business-accounting/Business Accounting.xlsx\")\n",
    "df = pd.read_excel(excel_path, sheet_name=5)\n",
    "print(f\"Loaded sheet with shape: {df.shape}\")\n",
    "\n",
    "# Quick preview for LLM context\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(df.head(10).to_string())\n",
    "print(\"\\nLast 5 rows:\")\n",
    "print(df.tail(5).to_string())\n",
    "\n",
    "# Get basic info\n",
    "sheet_name = \"None\"\n",
    "sheet_dimensions = f\"{df.shape[0]} rows x {df.shape[1]} columns\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a59279e",
   "metadata": {
    "cell_id": "6c1b7da2-b6b6-4016-b1e6-f1b67ee25296"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "excel_file_name = excel_path.name\n",
    "sheet_dimensions = f\"{df.shape[0]} rows x {df.shape[1]} columns\"\n",
    "sheet_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb7a647",
   "metadata": {
    "cell_id": "6ea03ca1-6cba-43f7-a41f-6050877e38d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA STRUCTURE ANALYSIS ===\nDataFrame shape: (47, 5)\nColumns: ['Date', 'Item', 'Amount (USD)', 'Amount (CFA)', 'Unnamed: 4']\n\n=== FIRST 10 ROWS ===\n                  Date                                       Item Amount (USD) Amount (CFA) Unnamed: 4\n0  2023-01-29 00:00:00                              Western Union    82.817929        50000        NaN\n1  2023-02-16 00:00:00                              Western Union       400.58       210000        NaN\n2  2023-04-27 00:00:00                               Sent to Papa     17096.69     10000000        NaN\n3  2023-05-30 00:00:00                   Sent to Yaya via Atchima       3414.2      2058000        NaN\n4  2023-06-02 00:00:00          Sent to Yaya via XE/Ria in Guinea       518.46       304168        NaN\n5  2023-06-06 00:00:00  Western Union to Abdoulaye Bamba for Yaya        48.41        28615        NaN\n6  2023-06-13 00:00:00                   Sent to Yaya via Atchima         5000      2994000        NaN\n7  2023-06-14 00:00:00                 Sent to Yaya via MoneyGram      1488.69       874000        NaN\n8  2023-06-21 00:00:00                 Sent to Yaya through Maman     37225.75     22000000        NaN\n9  2023-07-03 00:00:00            Sent to Yaya via XE/Ria in Mali      1668.96      1000000        NaN\n\n=== LAST 5 ROWS ===\n                Date     Item Amount (USD) Amount (CFA)  Unnamed: 4\n42  Chargement colis    37500    62.826347    62.826347           0\n43       Gazoil 200L   146000   244.603911   122.301956  122.301956\n44            Nattes     4000     6.701477     6.701477           0\n45     Shipping fees  2537550  4251.333256  4251.333256           0\n46             Total  3050050      5109.96   4862.00535   247.95465\n\n=== COLUMN ANALYSIS ===\nColumn 0 ('Date'): 27/47 non-null values\nColumn 1 ('Item'): 28/47 non-null values\nColumn 2 ('Amount (USD)'): 27/47 non-null values\nColumn 3 ('Amount (CFA)'): 28/47 non-null values\nColumn 4 ('Unnamed: 4'): 9/47 non-null values\n\n=== EMPTY ROW ANALYSIS ===\nEmpty rows found at indices: [19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n\n=== SIDE-BY-SIDE ANALYSIS ===\nLeft section shape: (47, 5)\nRight section shape: (47, 0)\nLeft section non-null density: 0.51\nRight section non-null density: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/jrpb86t115g40v7zwc3d5znw0000gn/T/ipykernel_15845/2689435735.py:32: RuntimeWarning: invalid value encountered in scalar divide\n  print(f\"Right section non-null density: {right_cols.notna().sum().sum() / (right_cols.shape[0] * right_cols.shape[1]):.2f}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Table Detection Analysis\n",
    "print(\"=== DATA STRUCTURE ANALYSIS ===\")\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\n=== FIRST 10 ROWS ===\")\n",
    "print(df.head(10).to_string())\n",
    "print(\"\\n=== LAST 5 ROWS ===\")\n",
    "print(df.tail(5).to_string())\n",
    "\n",
    "print(\"\\n=== COLUMN ANALYSIS ===\")\n",
    "# Check for empty columns that might separate tables\n",
    "for i, col in enumerate(df.columns):\n",
    "    non_null_count = df[col].notna().sum()\n",
    "    print(f\"Column {i} ('{col}'): {non_null_count}/{len(df)} non-null values\")\n",
    "\n",
    "print(\"\\n=== EMPTY ROW ANALYSIS ===\")\n",
    "# Check for empty rows that might separate tables\n",
    "empty_rows = df.isnull().all(axis=1)\n",
    "if empty_rows.any():\n",
    "    empty_row_indices = empty_rows[empty_rows].index.tolist()\n",
    "    print(f\"Empty rows found at indices: {empty_row_indices[:10]}\")\n",
    "else:\n",
    "    print(\"No completely empty rows found\")\n",
    "\n",
    "print(\"\\n=== SIDE-BY-SIDE ANALYSIS ===\")\n",
    "# Check for potential side-by-side tables by examining column groups\n",
    "left_cols = df.iloc[:, 0:7]  # First 7 columns\n",
    "right_cols = df.iloc[:, 7:]  # Remaining columns\n",
    "print(f\"Left section shape: {left_cols.shape}\")\n",
    "print(f\"Right section shape: {right_cols.shape}\")\n",
    "print(f\"Left section non-null density: {left_cols.notna().sum().sum() / (left_cols.shape[0] * left_cols.shape[1]):.2f}\")\n",
    "print(f\"Right section non-null density: {right_cols.notna().sum().sum() / (right_cols.shape[0] * right_cols.shape[1]):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f60b2b",
   "metadata": {
    "cell_id": "38112133-fab1-4cc9-86c3-d357e9377f42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 47 entries, 0 to 46\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   Date          27 non-null     object\n 1   Item          28 non-null     object\n 2   Amount (USD)  27 non-null     object\n 3   Amount (CFA)  28 non-null     object\n 4   Unnamed: 4    9 non-null      object\ndtypes: object(5)\nmemory usage: 2.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'start_row': 0,\n",
       "  'end_row': 18,\n",
       "  'start_col': 0,\n",
       "  'end_col': 4,\n",
       "  'description': 'Detected table based on non-empty data blocks',\n",
       "  'entity_type': 'business data',\n",
       "  'confidence': 0.8,\n",
       "  'table_type': 'DETAIL'},\n",
       " {'start_row': 38,\n",
       "  'end_row': 46,\n",
       "  'start_col': 0,\n",
       "  'end_col': 4,\n",
       "  'description': 'Detected table based on non-empty data blocks',\n",
       "  'entity_type': 'business data',\n",
       "  'confidence': 0.8,\n",
       "  'table_type': 'DETAIL'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the analysis results indicate a RuntimeWarning related to density calculation, it suggests that the data has some non-uniformity or missing values.\n",
    "# Let's examine the structure of the DataFrame to identify potential tables.\n",
    "\n",
    "# Check the shape, info, and a sample of the data\n",
    "info = df.info()\n",
    "head = df.head()\n",
    "shape = df.shape\n",
    "\n",
    "# Check for empty columns and rows to identify potential boundaries\n",
    "empty_rows = df.isnull().all(axis=1)\n",
    "empty_row_indices = empty_rows[empty_rows].index.tolist()\n",
    "empty_cols = df.isnull().all(axis=0)\n",
    "empty_col_indices = empty_cols[empty_cols].index.tolist()\n",
    "\n",
    "# Check for column patterns to identify different entity types or tables\n",
    "column_patterns = []\n",
    "for col in df.columns:\n",
    "    unique_vals = df[col].dropna().unique()\n",
    "    column_patterns.append((col, len(unique_vals)))\n",
    "\n",
    "# Based on the above, identify potential table boundaries\n",
    "# For simplicity, assume tables are separated by empty rows or columns\n",
    "# and look for clusters of non-empty data\n",
    "\n",
    "# Find start and end rows of tables based on non-empty data blocks\n",
    "import numpy as np\n",
    "non_empty_rows = ~empty_rows\n",
    "row_groups = []\n",
    "start_idx = None\n",
    "for idx, val in enumerate(non_empty_rows):\n",
    "    if val and start_idx is None:\n",
    "        start_idx = idx\n",
    "    elif not val and start_idx is not None:\n",
    "        row_groups.append((start_idx, idx - 1))\n",
    "        start_idx = None\n",
    "if start_idx is not None:\n",
    "    row_groups.append((start_idx, len(non_empty_rows) - 1))\n",
    "\n",
    "# Find start and end columns of tables based on non-empty columns\n",
    "non_empty_cols = ~empty_cols\n",
    "col_groups = []\n",
    "start_col_idx = None\n",
    "for idx, val in enumerate(non_empty_cols):\n",
    "    if val and start_col_idx is None:\n",
    "        start_col_idx = idx\n",
    "    elif not val and start_col_idx is not None:\n",
    "        col_groups.append((start_col_idx, idx - 1))\n",
    "        start_col_idx = None\n",
    "if start_col_idx is not None:\n",
    "    col_groups.append((start_col_idx, len(non_empty_cols) - 1))\n",
    "\n",
    "# Now, create table boundaries based on these groups\n",
    "# For each row group and column group, define a table\n",
    "# Filter out groups that are too small (less than 3 rows or columns)\n",
    "detected_tables = []\n",
    "for r_start, r_end in row_groups:\n",
    "    for c_start, c_end in col_groups:\n",
    "        if (r_end - r_start + 1) >= 3 and (c_end - c_start + 1) >= 3:\n",
    "            detected_tables.append({\n",
    "                \"start_row\": r_start,\n",
    "                \"end_row\": r_end,\n",
    "                \"start_col\": c_start,\n",
    "                \"end_col\": c_end,\n",
    "                \"description\": \"Detected table based on non-empty data blocks\",\n",
    "                \"entity_type\": \"business data\",\n",
    "                \"confidence\": 0.8,\n",
    "                \"table_type\": \"DETAIL\"\n",
    "            })\n",
    "\n",
    "# Output the detected tables\n",
    "detected_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a1dd7b0",
   "metadata": {
    "cell_id": "28ae3ad2-0889-4e7e-8f66-7ddf64b25d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 2 tables from LLM detection\n⚠️ Warning: First table missing fields: ['table_id']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'start_row': 0,\n",
       "  'end_row': 18,\n",
       "  'start_col': 0,\n",
       "  'end_col': 4,\n",
       "  'description': 'Detected table based on non-empty data blocks',\n",
       "  'entity_type': 'business data',\n",
       "  'confidence': 0.8,\n",
       "  'table_type': 'DETAIL'},\n",
       " {'start_row': 38,\n",
       "  'end_row': 46,\n",
       "  'start_col': 0,\n",
       "  'end_col': 4,\n",
       "  'description': 'Detected table based on non-empty data blocks',\n",
       "  'entity_type': 'business data',\n",
       "  'confidence': 0.8,\n",
       "  'table_type': 'DETAIL'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Extract detection results created by LLM\n",
    "# The detector should have created a 'detected_tables' variable with the results\n",
    "\n",
    "# CLAUDE-TEST-WORKAROUND: Validate that detected_tables exists and is properly formatted\n",
    "if 'detected_tables' in globals():\n",
    "    # Validate it's a list\n",
    "    if isinstance(detected_tables, list):\n",
    "        detection_results = detected_tables\n",
    "        print(f\"✅ Found {len(detection_results)} tables from LLM detection\")\n",
    "        # Validate first table has required fields (if any tables exist)\n",
    "        if detection_results:\n",
    "            required_fields = ['table_id', 'description', 'start_row', 'end_row', 'start_col', 'end_col']\n",
    "            first_table = detection_results[0]\n",
    "            missing_fields = [f for f in required_fields if f not in first_table]\n",
    "            if missing_fields:\n",
    "                print(f\"⚠️ Warning: First table missing fields: {missing_fields}\")\n",
    "    else:\n",
    "        print(f\"❌ Error: detected_tables is not a list, it's a {type(detected_tables)}\")\n",
    "        detection_results = []\n",
    "else:\n",
    "    # CLAUDE-GOTCHA: Gemini sometimes fails to create the variable even after multiple prompts\n",
    "    print(\"❌ No 'detected_tables' variable found - LLM failed to complete detection\")\n",
    "    detection_results = []\n",
    "\n",
    "detection_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d018db1",
   "metadata": {},
   "source": [
    "\n",
    "# Table Detection Results\n",
    "\n",
    "Detected 2 tables:\n",
    "\n",
    "\n",
    "## Table 1: Detected table based on non-empty data blocks\n",
    "- Location: Rows 0-18, Columns 0-4\n",
    "- Type: detail\n",
    "- Entity: business data\n",
    "- Confidence: 0.80\n",
    "\n",
    "## Table 2: Detected table based on non-empty data blocks\n",
    "- Location: Rows 38-46, Columns 0-4\n",
    "- Type: detail\n",
    "- Entity: business data\n",
    "- Confidence: 0.80\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
